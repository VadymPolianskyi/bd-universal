# 1. Dataset Example

## Instruction
1. Create Python proroject locally and in Git 
2. Install pyspark 
3. Download dataset from [Kagle](https://www.kaggle.com/datasets)
4. Create Spark session
5. Read `csv` dataset
6. Print Schema and Show a bit of data
7. Write dataset in formats `json`, `parquet`, `orc`


## Spark
In this example we're using Spark for reading the example Dataset 
in `csv` format and writing its' output in another file formats (`avro`, `parquet`, `orc`) 

[Overview](https://spark.apache.org/docs/latest/index.html)

Install Spark
```shell
pip install pyspark
```

## Parquet
Tool for queriing and reading `parquet` files
[parquet-tools](https://pypi.org/project/parquet-tools/)


## Resources
[Datasets locations]()
